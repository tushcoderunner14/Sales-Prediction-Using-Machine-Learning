# Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.colors as col
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

import datetime
from pathlib import Path
import random

# Scikit-Learn models
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from xgboost.sklearn import XGBRegressor
from sklearn.model_selection import KFold, cross_val_score, train_test_split

# LSTM
import keras
from keras.layers import Dense
from keras.models import Sequential
from keras.callbacks import EarlyStopping
from keras.utils import np_utils
from keras.layers import LSTM

# ARIMA Model
import statsmodels.tsa.api as smt
import statsmodels.api as sm
from statsmodels.tools.eval_measures import rmse

import pickle
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Loading and Exploration of the Data
dataset = pd.read_csv('../input/demand-forecasting-kernels-only/sample_submission.csv')
df = dataset.copy()
df.head()

def load_data(file_name):
    """Returns a pandas dataframe from a csv file."""
    return pd.read_csv(file_name)

df_s = load_data('../input/demand-forecasting-kernels-only/sample_submission.csv')
df_s.head()
df_s.tail()

# To view basic statistical details about dataset:
df_s['sales'].describe()
df_s['sales'].plot()

def monthlyORyears_sales(data, time=['monthly', 'years']):
    datadata = data.copy()
    if time == "monthly":
        # Drop the day indicator from the date column:
        datadata.date = data.date.apply(lambda x: str(x)[:-3])
    else:
        datadata.date = data.date.apply(lambda x: str(x)[:4])
        
    # Sum sales per month:
    datadata = data.groupby('date')['sales'].sum().reset_index()
    data.date = pd.to_datetime(data.date)
        
    return data

m_df = monthlyORyears_sales(df_s, "monthly")
m_df.to_csv('./monthly_data.csv')
m_df.head(10)

y_df = monthlyORyears_sales(df_s, "years")
y_df

layout = (1, 2)
raw = plt.subplot2grid(layout, (0, 0))
law = plt.subplot2grid(layout, (0, 1))

years = y_df['sales'].plot(kind="bar", color='mediumblue', label="Sales", ax=raw, figsize=(12, 5))
months = m_df['sales'].plot(marker='o', color='darkorange', label="Sales", ax=law)

years.set(xlabel="Years", title="Distribution of Sales Per Year")
months.set(xlabel="Months", title="Distribution of Sales Per Month")

sns.despine()
plt.tight_layout()

years.legend()
months.legend()

# EDA (Exploratory Data Analysis)
def sales_time(data):
    """Time interval of dataset:"""
    data.date = pd.to_datetime(data.date)
    n_of_days = data.date.max() - data.date.min()
    n_of_years = int(n_of_days.days / 365)
    
    print(f"Days: {n_of_days.days}\nYears: {n_of_years}\nMonth: {12 * n_of_years}")

sales_time(df_s)

def sales_per_store(data):
    sales_by_store = data.groupby('store')['sales'].sum().reset_index()
    
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.barplot(sales_by_store.store, sales_by_store.sales, color='darkred')
    
    ax.set(xlabel="Store Id", ylabel="Sum of Sales", title="Total Sales Per Store")
    
    return sales_by_store

sales_per_store(df_s)

# Overall for five years:
average_m_sales = m_df.sales.mean()
print(f"Overall Average Monthly Sales: ${average_m_sales}")

def avarage_12months():
    # Last one year (this will be the forecasted sales):
    average_m_sales_1y = m_df.sales[-12:].mean()
    print(f"Last 12 months average monthly sales: ${average_m_sales_1y}")

avarage_12months()

# Determining Time Series Stationary
def time_plot(data, x_col, y_col, title):
    fig, ax = plt.subplots(figsize=(15, 8))
    sns.lineplot(x_col, y_col, data=data, ax=ax, color='darkblue', label='Total Sales')
    
    s_mean = data.groupby(data.date.dt.year)[y_col].mean().reset_index()
    s_mean.date = pd.to_datetime(s_mean.date, format='%Y')
    sns.lineplot((s_mean.date + datetime.timedelta(6 * 365 / 12)), y_col, data=s_mean, ax=ax, color='red', label='Mean Sales')
    
    ax.set(xlabel="Years", ylabel="Sales", title=title)

time_plot(m_df, 'date', 'sales', 'Monthly Sales Before Diff Transformation')

# Differencing
def get_diff(data):
    """Calculate the difference in sales month over month:"""
    data['sales_diff'] = data.sales.diff()
    data = data.dropna()
    
    data.to_csv('./stationary_df.csv')
    
    return data

stationary_df = get_diff(m_df)
time_plot(stationary_df, 'date', 'sales_diff', 'Monthly Sales After Diff Transformation')

# ARIMA Modeling
def build_arima_data(data):
    """Generates a CSV file with a datetime index and a dependent sales column for ARIMA modelling."""
    da_data = data.set_index('date').drop('sales', axis=1)
    da_data.dropna(axis=0)
    
    da_data.to_csv('./arima_df.csv')
    
    return da_data

datatime_df = build_arima_data(stationary_df)
datatime_df # ARIMA Dataframe

# Observing Lags
def plots_lag(data, lags=None):
    """Convert dataframe to datetime index"""
    dt_data = data.set_index('date').drop('sales', axis=1)
    dt_data.dropna(axis=0)
    
    law = plt.subplot(122)
    acf = plt.subplot(221)
    pacf = plt.subplot(223)
    
    dt_data.plot(ax=law, figsize=(10, 5), color='orange')
    # Plot the autocorrelation function:
    smt.graphics.plot_acf(dt_data, lags=lags, ax=acf, color='mediumblue')
    smt.graphics.plot_pacf(dt_data, lags=lags, ax=pacf, color='mediumblue')
    
    # Will also adjust the spacing between subplots to minimize the overlaps:
    plt.tight_layout()

plots_lag(stationary_df, lags=24)

# Regressive Modeling
def built_supervised(data):
    supervised_df = data.copy()

    # Create a column for each lag:
    for i in range(1, 13):
        col_name = 'lag_' + str(i)
        supervised_df[col_name] = supervised_df['sales_diff'].shift(i)

    # Drop null values:
    supervised_df = supervised_df.dropna().reset_index(drop=True)

    supervised_df.to_csv('./model_df.csv', index=False)
    
    return supervised_df

model_df = built_supervised(stationary_df)
model_df
model_df.info() # Supervised Dataframe

# Train and Test Data
def train_test_split(data):
    data = data.drop(['sales', 'date'], axis=1)
    train, test = data[:-12].values, data[-12:].values
    
    return train, test

train, test = train_test_split(model_df)
print(f"Shape of Train: {train.shape}\nShape of Test: {test.shape}")

# Scaling Data
def scale_data(train_set, test_set):
    """Scales data using MinMaxScaler and separates data into X_train, y_train, X_test, and y_test."""
    # Apply Min Max Scaler:
    scaler = MinMaxScaler(feature_range=(-1, 1))
    scaler = scaler.fit(train_set)
    
    # Reshape training set:
    train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])
    train_set_scaled = scaler.transform(train_set)
    
    # Reshape test set:
    test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])
    test_set_scaled = scaler.transform(test_set)
    
    X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1].ravel() # returns the array, flattened!
    X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1].ravel()
    
    return X_train, y_train, X_test, y_test, scaler

X_train, y_train, X_test, y_test, scaler_object = scale_data(train, test)
print(f"Shape of X Train: {X_train.shape}\nShape of y Train: {y_train.shape}\nShape of X Test: {X_test.shape}\nShape of y Test: {y_test.shape}")

# Reverse Scaling
def re_scaling(y_pred, x_test, scaler_obj, lstm=False):
    """For visualizing and comparing results, undoes the scaling effect on predictions."""
    # y_pred: model predictions
    # x_test: features from the test set used for predictions
